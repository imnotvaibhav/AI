{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CEQtzFch_Z1F",
        "outputId": "8f3ee909-dc6d-4846-e71f-33293d03c556"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen[lmm]>=0.2.3\n",
            "  Downloading pyautogen-0.2.28-py3-none-any.whl (284 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flaml (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading FLAML-2.1.2-py3-none-any.whl (296 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.7/296.7 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from pyautogen[lmm]>=0.2.3) (1.25.2)\n",
            "Collecting openai>=1.3 (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading openai-1.34.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pyautogen[lmm]>=0.2.3) (24.1)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen[lmm]>=0.2.3) (2.7.3)\n",
            "Collecting python-dotenv (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen[lmm]>=0.2.3) (2.4.0)\n",
            "Collecting tiktoken (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pyautogen[lmm]>=0.2.3) (9.4.0)\n",
            "Collecting replicate (from pyautogen[lmm]>=0.2.3)\n",
            "  Downloading replicate-0.26.0-py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[lmm]>=0.2.3) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.3->pyautogen[lmm]>=0.2.3) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai>=1.3->pyautogen[lmm]>=0.2.3)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[lmm]>=0.2.3) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[lmm]>=0.2.3) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen[lmm]>=0.2.3) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[lmm]>=0.2.3) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen[lmm]>=0.2.3) (2.18.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen[lmm]>=0.2.3) (2.31.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker->pyautogen[lmm]>=0.2.3) (2.0.7)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen[lmm]>=0.2.3) (2024.5.15)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen[lmm]>=0.2.3) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen[lmm]>=0.2.3) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen[lmm]>=0.2.3) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai>=1.3->pyautogen[lmm]>=0.2.3)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen[lmm]>=0.2.3)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->docker->pyautogen[lmm]>=0.2.3) (3.3.2)\n",
            "Installing collected packages: python-dotenv, h11, flaml, diskcache, tiktoken, httpcore, docker, httpx, replicate, openai, pyautogen\n",
            "Successfully installed diskcache-5.6.3 docker-7.1.0 flaml-2.1.2 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.34.0 pyautogen-0.2.28 python-dotenv-1.0.1 replicate-0.26.0 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "pip install \"pyautogen[lmm]>=0.2.3\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We use this variable to control where you want to host LLaVA, locally or remotely?\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Type, Union\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "from termcolor import colored\n",
        "\n",
        "import autogen\n",
        "from autogen import Agent, AssistantAgent, ConversableAgent, UserProxyAgent\n",
        "from autogen.agentchat.contrib.llava_agent import LLaVAAgent, llava_call\n",
        "\n",
        "LLAVA_MODE = \"remote\"\n",
        "assert LLAVA_MODE in [\"local\", \"remote\"]"
      ],
      "metadata": {
        "id": "z2pu6YoD_doX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install replicate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyzwppvz_iOP",
        "outputId": "c72aef12-942a-4faf-aa06-5c11fbeb43be",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: replicate in /usr/local/lib/python3.10/dist-packages (0.26.0)\n",
            "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from replicate) (24.1)\n",
            "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.10/dist-packages (from replicate) (2.7.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from replicate) (4.12.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.21.0->replicate) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>1.10.7->replicate) (2.18.4)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u0Rf1Xbq_iZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using replicate api token"
      ],
      "metadata": {
        "id": "BiYqJLRjiEcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_9qvRRTQlLSOXd9nLnyJCh0AQ9F6gbWZ4738jF\""
      ],
      "metadata": {
        "id": "qshsnTWH_ie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if LLAVA_MODE == \"remote\":\n",
        "    import replicate\n",
        "\n",
        "    llava_config_list = [\n",
        "        {\n",
        "            \"model\": \"llava_model\",\n",
        "            \"api_key\": \"None\",\n",
        "            \"base_url\": \"yorickvp/llava-13b:2facb4a474a0462c15041b78b1ad70952ea46b5ec6ad29583c0b29dbd4249591\",\n",
        "        }\n",
        "    ]"
      ],
      "metadata": {
        "id": "MYXmdpew_ihy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vewMQiAU_ikf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_agent = LLaVAAgent(\n",
        "    name=\"image-explainer\",\n",
        "    max_consecutive_auto_reply=10,\n",
        "    llm_config={\"config_list\": llava_config_list, \"temperature\": 0.5, \"max_new_tokens\": 1000},\n",
        ")\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User_proxy\",\n",
        "    system_message=\"A human admin.\",\n",
        "    code_execution_config={\n",
        "        \"last_n_messages\": 3,\n",
        "        \"work_dir\": \"groupchat\",\n",
        "        \"use_docker\": False,\n",
        "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
        "    human_input_mode=\"NEVER\",  # Try between ALWAYS or NEVER\n",
        "    max_consecutive_auto_reply=0,\n",
        ")\n",
        "\n",
        "# Ask the question with an image\n",
        "user_proxy.initiate_chat(\n",
        "    image_agent,\n",
        "    message=\"\"\"What's the breed of this dog?\n",
        "<img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\"\"\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ne2YMurt_inJ",
        "outputId": "363df58e-4441-4353-ec67-7e5cdf53f091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User_proxy (to image-explainer):\n",
            "\n",
            "What's the breed of this dog?\n",
            "<image>.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            ">>>>>>>> USING AUTO REPLY...\n",
            "You are an AI agent and you can view images.\n",
            "###Human: What's the breed of this dog?\n",
            "<image>.\n",
            "\n",
            "###Assistant: \n",
            "image-explainer (to User_proxy):\n",
            "\n",
            "The dog in the image is a poodle.\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatResult(chat_id=None, chat_history=[{'content': \"What's the breed of this dog?\\n<img https://th.bing.com/th/id/R.422068ce8af4e15b0634fe2540adea7a?rik=y4OcXBE%2fqutDOw&pid=ImgRaw&r=0>.\", 'role': 'assistant'}, {'content': 'The dog in the image is a poodle.', 'role': 'user'}], summary='The dog in the image is a poodle.', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=[])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### DOG WAS POODLE ####"
      ],
      "metadata": {
        "id": "rAJ8nFiMily9"
      }
    }
  ]
}